/**
 * éŸ³é¢‘æœåŠ¡
 * è´Ÿè´£è§†é¢‘éŸ³é¢‘çš„ç”Ÿæˆï¼ŒåŒ…æ‹¬ TTS è¯­éŸ³åˆæˆå’ŒèƒŒæ™¯éŸ³ä¹å¤„ç†
 */

import { exec } from 'child_process';
import { promisify } from 'util';
import fs from 'fs-extra';
import path from 'path';
import os from 'os';
import { VolcanoTTSService } from './volcano-tts-service';
import { AliyunTTSService } from './aliyun-tts-service';

const execAsync = promisify(exec);

export interface TTSOptions {
  voice?: string;      // è¯­éŸ³é€‰æ‹©
  speed?: number;      // è¯­é€Ÿ (0.5-2.0)
  pitch?: number;      // éŸ³è°ƒ (-50 to +50)
  volume?: number;     // éŸ³é‡ (0-100)
  emotion?: string;    // æƒ…ç»ªï¼ˆç”¨äºé€‰æ‹©åˆé€‚çš„è¯­éŸ³é£æ ¼ï¼‰
  engine?: 'edge-tts' | 'macos-say' | 'volcano' | 'aliyun' | 'auto';  // TTS å¼•æ“
}

export interface AudioSegment {
  text: string;
  start: number;    // å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
  end: number;      // ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
  options?: TTSOptions;
}

export interface TTSEngine {
  name: string;
  available: boolean;
  voices?: string[];
}

export class AudioService {
  private tempDir: string;
  private availableEngines: Map<string, TTSEngine> = new Map();
  private volcanoTTS?: VolcanoTTSService;
  private aliyunTTS?: AliyunTTSService;

  constructor() {
    // åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå­˜å‚¨éŸ³é¢‘æ–‡ä»¶
    this.tempDir = path.join(os.tmpdir(), 'movieflow-audio');
    fs.ensureDirSync(this.tempDir);

    // åˆå§‹åŒ–æ—¶æ£€æµ‹å¯ç”¨çš„ TTS å¼•æ“
    this.detectAvailableEngines();
  }

  /**
   * æ£€æµ‹å¯ç”¨çš„ TTS å¼•æ“
   */
  async detectAvailableEngines(): Promise<Map<string, TTSEngine>> {
    // æ£€æµ‹ edge-tts
    try {
      await execAsync('which edge-tts');
      this.availableEngines.set('edge-tts', {
        name: 'Microsoft Edge TTS',
        available: true,
        voices: [
          'zh-CN-XiaoxiaoNeural',  // å¥³å£°-æ™“æ™“
          'zh-CN-YunxiNeural',     // ç”·å£°-äº‘å¸Œ
          'zh-CN-XiaoyiNeural',    // å¥³å£°-æ™“ä¼Š
          'zh-CN-YunjianNeural'    // ç”·å£°-äº‘å¥
        ]
      });
    } catch {
      this.availableEngines.set('edge-tts', {
        name: 'Microsoft Edge TTS',
        available: false
      });
    }

    // æ£€æµ‹ macOS say å‘½ä»¤
    try {
      await execAsync('which say');
      const { stdout } = await execAsync('say -v ?');
      const chineseVoices = stdout.split('\n')
        .filter(line => line.includes('zh'))
        .map(line => line.split(/\s+/)[0]);

      this.availableEngines.set('macos-say', {
        name: 'macOS Text to Speech',
        available: true,
        voices: chineseVoices
      });
    } catch {
      this.availableEngines.set('macos-say', {
        name: 'macOS Text to Speech',
        available: false
      });
    }

    // æ£€æµ‹é˜¿é‡Œäº‘ TTS
    const aliyunAppKey = process.env.ALIYUN_TTS_APP_KEY;
    const aliyunToken = process.env.ALIYUN_TTS_TOKEN;
    if (aliyunAppKey && aliyunToken) {
      this.availableEngines.set('aliyun', {
        name: 'Aliyun TTS (é˜¿é‡Œäº‘è¯­éŸ³åˆæˆ)',
        available: true,
        voices: [
          'xiaoyun', // æ ‡å‡†å¥³å£°
          'xiaogang', // æ ‡å‡†ç”·å£°
          'aiyue', // æ¸©æŸ”å¥³å£°
          'aixia', // æ´»æ³¼å¥³å£°
        ]
      });

      // åˆå§‹åŒ–é˜¿é‡Œäº‘ TTS æœåŠ¡
      this.aliyunTTS = new AliyunTTSService({
        appKey: aliyunAppKey,
        token: aliyunToken
      });
    } else {
      this.availableEngines.set('aliyun', {
        name: 'Aliyun TTS (é˜¿é‡Œäº‘è¯­éŸ³åˆæˆ)',
        available: false
      });
    }

    // æ£€æµ‹ç«å±±å¼•æ“ TTS
    const volcanoAppId = process.env.VOLCANO_TTS_APP_ID;
    const volcanoToken = process.env.VOLCANO_TTS_TOKEN;
    if (volcanoAppId && volcanoToken) {
      this.availableEngines.set('volcano', {
        name: 'Volcano Engine TTS (è±†åŒ…è¯­éŸ³)',
        available: true,
        voices: [
          'zh_female_cancan_mars_bigtts', // å¤§æ¨¡å‹å¥³å£°
          'zh_male_M392_conversation_wvae_bigtts', // å¤§æ¨¡å‹ç”·å£°
          'BV700_streaming', // é€šç”¨å¥³å£°
          'BV001_streaming', // é€šç”¨ç”·å£°
        ]
      });

      // åˆå§‹åŒ–ç«å±±å¼•æ“ TTS æœåŠ¡
      this.volcanoTTS = new VolcanoTTSService({
        appId: volcanoAppId,
        accessToken: volcanoToken,
        secretKey: process.env.VOLCANO_TTS_SECRET
      });
    } else {
      this.availableEngines.set('volcano', {
        name: 'Volcano Engine TTS (è±†åŒ…è¯­éŸ³)',
        available: false
      });
    }

    return this.availableEngines;
  }

  /**
   * ç”Ÿæˆå•ä¸ªè¯­éŸ³ç‰‡æ®µ
   */
  async generateSpeech(
    text: string,
    options: TTSOptions = {}
  ): Promise<string> {
    const engine = await this.selectEngine(options.engine);
    const outputPath = path.join(
      this.tempDir,
      `speech_${Date.now()}.mp3`
    );

    // å°è¯•ä½¿ç”¨é€‰å®šçš„å¼•æ“ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨é™çº§
    let enginesAttempted = new Set<string>();
    let currentEngine = engine;

    while (currentEngine !== 'silent') {
      try {
        if (currentEngine === 'aliyun' && this.aliyunTTS) {
          // ä½¿ç”¨é˜¿é‡Œäº‘TTS
          console.log(`â˜ï¸ å°è¯•ä½¿ç”¨é˜¿é‡Œäº‘TTS...`);
          const audioPath = await this.aliyunTTS.synthesize({
            text,
            voice: options.voice || 'xiaoyun',  // é»˜è®¤ä½¿ç”¨å°äº‘å¥³å£°
            speed: options.speed ? (options.speed - 1) * 500 : 0,  // è½¬æ¢ä¸ºé˜¿é‡Œäº‘çš„èŒƒå›´ -500~500
            volume: options.volume || 50,
            pitch: options.pitch || 0,
            format: 'mp3'
          });
          // å°†ç”Ÿæˆçš„æ–‡ä»¶ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
          await fs.move(audioPath, outputPath, { overwrite: true });
          console.log(`âœ… é˜¿é‡Œäº‘TTSæˆåŠŸ`);
          return outputPath;
        } else if (currentEngine === 'volcano' && this.volcanoTTS) {
          // ä½¿ç”¨ç«å±±å¼•æ“TTS
          console.log(`ğŸŒ‹ å°è¯•ä½¿ç”¨ç«å±±å¼•æ“TTS...`);
          const audioPath = await this.volcanoTTS.synthesize({
            text,
            voice: options.voice || 'zh_female_cancan_mars_bigtts',  // é»˜è®¤ä½¿ç”¨å¤§æ¨¡å‹å¥³å£°
            speed: options.speed,
            volume: options.volume ? options.volume / 100 : undefined,
            pitch: options.pitch,
            emotion: options.emotion,
            format: 'mp3'
          });
          // å°†ç”Ÿæˆçš„æ–‡ä»¶ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
          await fs.move(audioPath, outputPath, { overwrite: true });
          console.log(`âœ… ç«å±±å¼•æ“TTSæˆåŠŸ`);
          return outputPath;
        } else if (currentEngine === 'edge-tts') {
          console.log(`ğŸŒ å°è¯•ä½¿ç”¨Edge-TTS...`);
          await this.generateWithEdgeTTS(text, outputPath, options);
          console.log(`âœ… Edge-TTSæˆåŠŸ`);
          return outputPath;
        } else if (currentEngine === 'macos-say') {
          console.log(`ğŸ å°è¯•ä½¿ç”¨macOS Say...`);
          await this.generateWithMacOSSay(text, outputPath, options);
          console.log(`âœ… macOS SayæˆåŠŸ`);
          return outputPath;
        }
      } catch (error: any) {
        console.error(`âš ï¸  ${currentEngine} å¤±è´¥: ${error.message}`);
        enginesAttempted.add(currentEngine);

        // è·å–ä¸‹ä¸€ä¸ªå¯ç”¨å¼•æ“
        currentEngine = await this.getNextAvailableEngine(enginesAttempted);
        if (currentEngine !== 'silent') {
          console.log(`ğŸ”„ é™çº§åˆ°: ${currentEngine}`);
        }
      }
    }

    // å¦‚æœæ‰€æœ‰å¼•æ“éƒ½å¤±è´¥ï¼Œç”Ÿæˆé™éŸ³éŸ³é¢‘
    console.warn(`ğŸ”‡ æ‰€æœ‰TTSå¼•æ“éƒ½å¤±è´¥ï¼Œç”Ÿæˆé™éŸ³éŸ³é¢‘`);
    await this.generateSilentAudio(outputPath, 10);
    return outputPath;
  }

  /**
   * ä½¿ç”¨ edge-tts ç”Ÿæˆè¯­éŸ³
   */
  private async generateWithEdgeTTS(
    text: string,
    outputPath: string,
    options: TTSOptions
  ): Promise<void> {
    const voice = options.voice || 'zh-CN-YunxiNeural';
    const rate = options.speed ? `${Math.round((options.speed - 1) * 100)}%` : '+0%';
    const pitch = options.pitch ? `${options.pitch}Hz` : '+0Hz';
    const volume = options.volume ? `${options.volume}` : '100';

    const command = `edge-tts --voice "${voice}" --rate "${rate}" --pitch "${pitch}" --volume "${volume}" --text "${text}" --write-media "${outputPath}"`;

    await execAsync(command);
  }

  /**
   * ä½¿ç”¨ macOS say å‘½ä»¤ç”Ÿæˆè¯­éŸ³
   */
  private async generateWithMacOSSay(
    text: string,
    outputPath: string,
    options: TTSOptions
  ): Promise<void> {
    const voice = options.voice || 'Tingting';
    const rate = options.speed ? Math.round(options.speed * 200) : 200;

    // macOS say å…ˆç”Ÿæˆ AIFFï¼Œç„¶åè½¬æ¢ä¸º MP3
    const tempAiff = outputPath.replace('.mp3', '.aiff');
    const sayCommand = `say -v "${voice}" -r ${rate} "${text}" -o "${tempAiff}"`;
    const convertCommand = `ffmpeg -i "${tempAiff}" -acodec mp3 -ab 192k "${outputPath}" -y && rm "${tempAiff}"`;

    await execAsync(sayCommand);
    await execAsync(convertCommand);
  }

  /**
   * ç”Ÿæˆé™éŸ³éŸ³é¢‘ï¼ˆä½œä¸ºåå¤‡æ–¹æ¡ˆï¼‰
   */
  private async generateSilentAudio(
    outputPath: string,
    duration: number
  ): Promise<void> {
    const command = `ffmpeg -f lavfi -i anullsrc=r=44100:cl=mono -t ${duration} -acodec mp3 "${outputPath}" -y`;
    await execAsync(command);
  }

  /**
   * é€‰æ‹©åˆé€‚çš„ TTS å¼•æ“
   */
  private async selectEngine(
    preferredEngine?: string
  ): Promise<string> {
    if (preferredEngine && preferredEngine !== 'auto') {
      const engine = this.availableEngines.get(preferredEngine);
      if (engine?.available) {
        return preferredEngine;
      }
    }

    // è‡ªåŠ¨é€‰æ‹©ï¼šä¼˜å…ˆé˜¿é‡Œäº‘TTSï¼Œå…¶æ¬¡ç«å±±å¼•æ“TTSï¼Œç„¶å edge-ttsï¼Œæœ€å macOS say
    if (this.availableEngines.get('aliyun')?.available) {
      return 'aliyun';
    }
    if (this.availableEngines.get('volcano')?.available) {
      return 'volcano';
    }
    if (this.availableEngines.get('edge-tts')?.available) {
      return 'edge-tts';
    }
    if (this.availableEngines.get('macos-say')?.available) {
      return 'macos-say';
    }

    return 'silent';
  }

  /**
   * è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„TTSå¼•æ“ï¼ˆç”¨äºé™çº§ï¼‰
   */
  private async getNextAvailableEngine(
    attempted: Set<string>
  ): Promise<string> {
    const enginePriority = ['aliyun', 'volcano', 'edge-tts', 'macos-say'];

    for (const engine of enginePriority) {
      if (!attempted.has(engine) && this.availableEngines.get(engine)?.available) {
        return engine;
      }
    }

    return 'silent';
  }

  /**
   * æ ¹æ®åœºæ™¯æ®µè½ç”ŸæˆéŸ³é¢‘
   */
  async generateFromSegments(
    segments: AudioSegment[]
  ): Promise<string> {
    const audioFiles: string[] = [];

    // ä¸ºæ¯ä¸ªç‰‡æ®µç”ŸæˆéŸ³é¢‘
    for (const segment of segments) {
      const audioPath = await this.generateSpeech(
        segment.text,
        segment.options
      );

      // è°ƒæ•´éŸ³é¢‘æ—¶é•¿ä»¥åŒ¹é…åœºæ™¯æ—¶é•¿
      const duration = segment.end - segment.start;
      const adjustedPath = await this.adjustAudioDuration(
        audioPath,
        duration
      );

      audioFiles.push(adjustedPath);
    }

    // åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
    return await this.mergeAudioFiles(audioFiles);
  }

  /**
   * è°ƒæ•´éŸ³é¢‘æ—¶é•¿
   */
  private async adjustAudioDuration(
    audioPath: string,
    targetDuration: number
  ): Promise<string> {
    const outputPath = audioPath.replace('.mp3', '_adjusted.mp3');

    // è·å–åŸå§‹éŸ³é¢‘æ—¶é•¿
    const { stdout } = await execAsync(
      `ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "${audioPath}"`
    );
    const originalDuration = parseFloat(stdout.trim());

    if (Math.abs(originalDuration - targetDuration) < 0.5) {
      // å¦‚æœæ—¶é•¿å·®å¼‚å°äº 0.5 ç§’ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–‡ä»¶
      return audioPath;
    }

    // atempo çš„æœ‰æ•ˆèŒƒå›´æ˜¯ 0.5 åˆ° 100
    // å¦‚æœéœ€è¦çš„é€Ÿåº¦å˜åŒ–è¶…å‡ºè¿™ä¸ªèŒƒå›´ï¼Œéœ€è¦é“¾å¼ä½¿ç”¨å¤šä¸ª atempo
    let tempo = originalDuration / targetDuration;
    let filterChain = '';

    if (tempo < 0.5) {
      // éŸ³é¢‘å¤ªçŸ­ï¼Œéœ€è¦å‡é€Ÿï¼ˆæ‹‰é•¿ï¼‰
      // ä½¿ç”¨å¤šä¸ª atempo=0.5 é“¾å¼å¤„ç†
      while (tempo < 0.5) {
        filterChain += 'atempo=0.5,';
        tempo *= 2;
      }
      filterChain += `atempo=${tempo}`;
    } else if (tempo > 100) {
      // éŸ³é¢‘å¤ªé•¿ï¼Œéœ€è¦åŠ é€Ÿï¼ˆç¼©çŸ­ï¼‰
      // ä½¿ç”¨å¤šä¸ª atempo=100 é“¾å¼å¤„ç†
      while (tempo > 100) {
        filterChain += 'atempo=100,';
        tempo /= 100;
      }
      filterChain += `atempo=${tempo}`;
    } else {
      // åœ¨æ­£å¸¸èŒƒå›´å†…
      filterChain = `atempo=${tempo}`;
    }

    // å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œå¯ä»¥é€‰æ‹©å¡«å……é™éŸ³è€Œä¸æ˜¯æ‹‰ä¼¸
    if (originalDuration < targetDuration * 0.3) {
      // éŸ³é¢‘å°äºç›®æ ‡æ—¶é•¿çš„30%ï¼Œä½¿ç”¨å¡«å……é™éŸ³çš„æ–¹å¼
      const silenceDuration = targetDuration - originalDuration;
      const command = `ffmpeg -i "${audioPath}" -f lavfi -i anullsrc=r=44100:cl=mono -t ${silenceDuration} -filter_complex "[0:a][1:a]concat=n=2:v=0:a=1" "${outputPath}" -y`;
      await execAsync(command);
    } else {
      // ä½¿ç”¨ atempo è°ƒæ•´é€Ÿåº¦
      const command = `ffmpeg -i "${audioPath}" -filter:a "${filterChain}" "${outputPath}" -y`;
      await execAsync(command);
    }

    return outputPath;
  }

  /**
   * åˆå¹¶å¤šä¸ªéŸ³é¢‘æ–‡ä»¶
   */
  async mergeAudioFiles(
    audioFiles: string[]
  ): Promise<string> {
    if (audioFiles.length === 0) {
      throw new Error('æ²¡æœ‰æä¾›è¦åˆå¹¶çš„éŸ³é¢‘æ–‡ä»¶');
    }

    if (audioFiles.length === 1) {
      return audioFiles[0];
    }

    const outputPath = path.join(
      this.tempDir,
      `merged_${Date.now()}.mp3`
    );

    // åˆ›å»ºæ–‡ä»¶åˆ—è¡¨
    const listPath = path.join(this.tempDir, `merge_list_${Date.now()}.txt`);
    const fileList = audioFiles
      .map(file => `file '${file}'`)
      .join('\n');
    await fs.writeFile(listPath, fileList);

    // ä½¿ç”¨ FFmpeg åˆå¹¶éŸ³é¢‘
    const command = `ffmpeg -f concat -safe 0 -i "${listPath}" -c copy "${outputPath}" -y`;
    await execAsync(command);

    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    await fs.remove(listPath);

    return outputPath;
  }

  /**
   * æ·»åŠ èƒŒæ™¯éŸ³ä¹
   */
  async addBackgroundMusic(
    voicePath: string,
    musicPath: string,
    options: {
      musicVolume?: number;  // èƒŒæ™¯éŸ³ä¹éŸ³é‡ (0-1)
      fadeIn?: number;       // æ·¡å…¥æ—¶é•¿ï¼ˆç§’ï¼‰
      fadeOut?: number;      // æ·¡å‡ºæ—¶é•¿ï¼ˆç§’ï¼‰
    } = {}
  ): Promise<string> {
    const outputPath = path.join(
      this.tempDir,
      `with_music_${Date.now()}.mp3`
    );

    const musicVolume = options.musicVolume || 0.3;
    const fadeIn = options.fadeIn || 2;
    const fadeOut = options.fadeOut || 2;

    // è·å–è¯­éŸ³æ—¶é•¿
    const { stdout } = await execAsync(
      `ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "${voicePath}"`
    );
    const duration = parseFloat(stdout.trim());

    // æ··åˆè¯­éŸ³å’ŒèƒŒæ™¯éŸ³ä¹
    const command = `ffmpeg -i "${voicePath}" -i "${musicPath}" \
      -filter_complex "[1:a]volume=${musicVolume},afade=in:st=0:d=${fadeIn},afade=out:st=${duration - fadeOut}:d=${fadeOut}[music]; \
      [0:a][music]amix=inputs=2:duration=shortest[out]" \
      -map "[out]" "${outputPath}" -y`;

    await execAsync(command);
    return outputPath;
  }

  /**
   * æ ¹æ®æƒ…ç»ªé€‰æ‹©èƒŒæ™¯éŸ³ä¹
   */
  selectBackgroundMusic(
    emotion: string,
    duration: number
  ): string {
    // è¿™é‡Œåº”è¯¥æœ‰ä¸€ä¸ªéŸ³ä¹åº“çš„æ˜ å°„
    // æš‚æ—¶è¿”å›å ä½è·¯å¾„
    const musicLibrary: Record<string, string> = {
      happy: 'assets/music/happy.mp3',
      sad: 'assets/music/sad.mp3',
      exciting: 'assets/music/exciting.mp3',
      calm: 'assets/music/calm.mp3',
      serious: 'assets/music/serious.mp3'
    };

    return musicLibrary[emotion] || musicLibrary.calm;
  }

  /**
   * æ¸…ç†ä¸´æ—¶æ–‡ä»¶
   */
  async cleanup(): Promise<void> {
    await fs.emptyDir(this.tempDir);
  }

  /**
   * è·å–å¯ç”¨çš„è¯­éŸ³åˆ—è¡¨
   */
  getAvailableVoices(engine?: string): string[] {
    if (engine) {
      return this.availableEngines.get(engine)?.voices || [];
    }

    const voices: string[] = [];
    for (const [, engineInfo] of this.availableEngines) {
      if (engineInfo.available && engineInfo.voices) {
        voices.push(...engineInfo.voices);
      }
    }
    return voices;
  }
}